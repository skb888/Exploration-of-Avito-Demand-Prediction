{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# speed up the loop\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", parse_dates=[\"activation_date\"])\n",
    "test_df = pd.read_csv(\"test.csv\", parse_dates=[\"activation_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = train_df[\"deal_probability\"].values\n",
    "test_id = test_df[\"item_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"activation_weekday\"] = train_df[\"activation_date\"].dt.weekday\n",
    "train_df[\"activation_week\"] = train_df[\"activation_date\"].dt.week\n",
    "train_df[\"activation_day\"] = train_df[\"activation_date\"].dt.day\n",
    "\n",
    "test_df[\"activation_weekday\"] = test_df[\"activation_date\"].dt.weekday\n",
    "test_df[\"activation_week\"] = test_df[\"activation_date\"].dt.week\n",
    "test_df[\"activation_day\"] = test_df[\"activation_date\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = pd.concat([train_df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"image_top_1\"].fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"price\"] = np.log(data[\"price\"]+0.001)\n",
    "data[\"price\"].fillna(data.price.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.24it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "category_column = ['region','city','parent_category_name','category_name','user_type','image_top_1','item_seq_number','activation_weekday','activation_week','activation_day']\n",
    "for item in tqdm(category_column):\n",
    "        groupBy = train_df.groupby(item)['deal_probability']\n",
    "        mean = groupBy.mean()\n",
    "        std = groupBy.std()\n",
    "        data[item + '_deal_probability_mean'] = data[item].map(mean)\n",
    "        data[item + '_deal_probability_std'] = data[item].map(std)\n",
    "\n",
    "\n",
    "for item in tqdm(category_column):\n",
    "        groupBy = train_df.groupby(item)['price']\n",
    "        mean = groupBy.mean()\n",
    "        std = groupBy.std()\n",
    "        data[item + '_price_mean'] = data[item].map(mean)\n",
    "        data[item + '_price_std'] = data[item].map(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=200, stop_words = stopWords)\n",
    "tfidf_title = TfidfVectorizer(max_features=100, stop_words = stopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=100, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', '...гда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между'],\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['description'] = train_df['description'].fillna(' ')\n",
    "test_df['description'] = test_df['description'].fillna(' ')\n",
    "train_df['title'] = train_df['title'].fillna(' ')\n",
    "test_df['title'] = test_df['title'].fillna(' ')\n",
    "tfidf.fit(pd.concat([train_df['description'], test_df['description']]))\n",
    "tfidf_title.fit(pd.concat([train_df['title'], test_df['title']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_des_tfidf = tfidf.transform(train_df['description'])\n",
    "test_des_tfidf = tfidf.transform(test_df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_tfidf = tfidf.transform(train_df['title'])\n",
    "test_title_tfidf = tfidf.transform(test_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='arpack', n_components=5, n_iter=5, random_state=None,\n",
       "       tol=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_comp = 5\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_obj.fit(tfidf.transform(pd.concat([train_df['description'], test_df['description']])))\n",
    "\n",
    "svd_title = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "svd_title.fit(tfidf.transform(pd.concat([train_df['title'], test_df['title']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_svd = pd.DataFrame(svd_obj.transform(train_des_tfidf))\n",
    "test_svd = pd.DataFrame(svd_obj.transform(test_des_tfidf))\n",
    "train_svd.columns = ['svd_des_'+str(i+1) for i in range(n_comp)]\n",
    "test_svd.columns = ['svd_des_'+str(i+1) for i in range(n_comp)]\n",
    "train_df = pd.concat([train_df, train_svd], axis=1)\n",
    "test_df = pd.concat([test_df, test_svd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_svd = pd.DataFrame(svd_title.transform(train_title_tfidf))\n",
    "test_titile_svd = pd.DataFrame(svd_title.transform(test_title_tfidf))\n",
    "train_title_svd.columns = ['svd_title_'+str(i+1) for i in range(n_comp)]\n",
    "test_titile_svd.columns = ['svd_title_'+str(i+1) for i in range(n_comp)]\n",
    "train_df = pd.concat([train_df, train_title_svd], axis=1)\n",
    "test_df = pd.concat([test_df, test_titile_svd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:48<00:00,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['item_id', 'user_id', 'region', 'city', 'parent_category_name',\n",
      "       'category_name', 'param_1', 'param_2', 'param_3', 'title',\n",
      "       'description', 'price', 'item_seq_number', 'activation_date',\n",
      "       'user_type', 'image', 'image_top_1', 'deal_probability',\n",
      "       'activation_weekday', 'activation_week', 'activation_day', 'svd_des_1',\n",
      "       'svd_des_2', 'svd_des_3', 'svd_des_4', 'svd_des_5', 'svd_title_1',\n",
      "       'svd_title_2', 'svd_title_3', 'svd_title_4', 'svd_title_5'],\n",
      "      dtype='object')\n",
      "   region  city  parent_category_name  category_name  param_1  param_2  \\\n",
      "0      11  1156                     4             37      167       16   \n",
      "1       9   352                     2             15       27       16   \n",
      "2       8   325                     0             12      355       16   \n",
      "3      14  1698                     4             37      304       16   \n",
      "4      22   996                     6              0      199       29   \n",
      "\n",
      "   param_3    price  item_seq_number  user_type     ...       svd_des_1  \\\n",
      "0      244    400.0                2          1     ...        0.053017   \n",
      "1      244   3000.0               19          1     ...        0.000000   \n",
      "2      244   4000.0                9          1     ...        0.372024   \n",
      "3      244   2200.0              286          0     ...        0.491043   \n",
      "4      678  40000.0                3          1     ...        0.040537   \n",
      "\n",
      "   svd_des_2  svd_des_3  svd_des_4  svd_des_5  svd_title_1  svd_title_2  \\\n",
      "0   0.034130   0.067921   0.059364  -0.002014          0.0          0.0   \n",
      "1   0.000000   0.000000   0.000000   0.000000          0.0          0.0   \n",
      "2  -0.226229   0.022060  -0.095704  -0.246020          0.0          0.0   \n",
      "3   0.670496  -0.533965  -0.073032   0.017537          0.0          0.0   \n",
      "4   0.015097   0.019077  -0.008766  -0.016149          0.0          0.0   \n",
      "\n",
      "   svd_title_3  svd_title_4  svd_title_5  \n",
      "0          0.0          0.0          0.0  \n",
      "1          0.0          0.0          0.0  \n",
      "2          0.0          0.0          0.0  \n",
      "3          0.0          0.0          0.0  \n",
      "4          0.0          0.0          0.0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Label encode the categorical variables #\n",
    "cat_vars = [\"region\", \"city\", \"parent_category_name\", \"category_name\", \"user_type\", \"param_1\", \"param_2\", \"param_3\"]\n",
    "for col in tqdm(cat_vars):\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[col].values.astype('str')) + list(test_df[col].values.astype('str')))\n",
    "    train_df[col] = lbl.transform(list(train_df[col].values.astype('str')))\n",
    "    test_df[col] = lbl.transform(list(test_df[col].values.astype('str')))\n",
    "\n",
    "cols_to_drop = [\"item_id\", \"user_id\", \"title\", \"description\", \"activation_date\", \"image\"]\n",
    "print(train_df.columns)\n",
    "train_X = train_df.drop(cols_to_drop + [\"deal_probability\"], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "print(train_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503424, 24) (508438, 24)\n"
     ]
    }
   ],
   "source": [
    "print (train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2011862, 61)\n"
     ]
    }
   ],
   "source": [
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_period = pd.read_pickle('period.p')\n",
    "test_period = pd.read_pickle('test_period.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_price_rank = pd.read_pickle('price_rank_train.p')\n",
    "test_price_rank = pd.read_pickle('price_rank_test.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, train_period, train_price_rank], axis=1)\n",
    "test_df = pd.concat([test_df, test_period, test_price_rank], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region  city  parent_category_name  category_name  param_1  param_2  \\\n",
      "0      19   462                     4             42      249      112   \n",
      "1      17  1314                     2             22      122      112   \n",
      "2      16  1290                     0              2       84      112   \n",
      "3      21   950                     4             42       38      112   \n",
      "4       4   318                     6              0      278      124   \n",
      "\n",
      "   param_3    price  item_seq_number  user_type     ...       svd_title_3  \\\n",
      "0     1217    400.0                2          1     ...               0.0   \n",
      "1     1217   3000.0               19          1     ...               0.0   \n",
      "2     1217   4000.0                9          1     ...               0.0   \n",
      "3     1217   2200.0              286          0     ...               0.0   \n",
      "4       46  40000.0                3          1     ...               0.0   \n",
      "\n",
      "   svd_title_4  svd_title_5  svd_title_6  svd_title_7  svd_title_8  \\\n",
      "0          0.0          0.0          0.0          0.0          0.0   \n",
      "1          0.0          0.0          0.0          0.0          0.0   \n",
      "2          0.0          0.0          0.0          0.0          0.0   \n",
      "3          0.0          0.0          0.0          0.0          0.0   \n",
      "4          0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "   svd_title_9  svd_title_10  diff  price_rank1  \n",
      "0          0.0           0.0    13     0.830366  \n",
      "1          0.0           0.0    13     0.493957  \n",
      "2          0.0           0.0     5     0.314507  \n",
      "3          0.0           0.0     8     0.383375  \n",
      "4          0.0           0.0    13     0.930585  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "train_X = train_df.drop(cols_to_drop + [\"deal_probability\"], axis=1)\n",
    "test_X = test_df.drop(cols_to_drop, axis=1)\n",
    "\n",
    "print(train_X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(train_X, train_y, val_X, val_y, test_X):\n",
    "    params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\",\n",
    "        \"num_leaves\" : 40,\n",
    "        \"learning_rate\" : 0.09,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.7,\n",
    "        #\"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"verbosity\" : -1\n",
    "    }\n",
    "    \n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "    lgval = lgb.Dataset(val_X, label=val_y)\n",
    "    evals_result = {}\n",
    "    model = lgb.train(params, lgtrain, 6000, valid_sets=[lgval], early_stopping_rounds=150, verbose_eval=20, evals_result=evals_result)\n",
    "    \n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    return pred_test_y, model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1303424, 24) (200000, 24) (1303424,) (200000,) (508438, 24)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data for model training#\n",
    "dev_X = train_X.iloc[:-200000,:]\n",
    "val_X = train_X.iloc[-200000:,:]\n",
    "train_y = train_df[\"deal_probability\"].values\n",
    "dev_y = train_y[:-200000]\n",
    "val_y = train_y[-200000:]\n",
    "print(dev_X.shape, val_X.shape, dev_y.shape, val_y.shape, test_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds.\n",
      "[20]\tvalid_0's rmse: 0.235521\n",
      "[40]\tvalid_0's rmse: 0.232333\n",
      "[60]\tvalid_0's rmse: 0.231138\n",
      "[80]\tvalid_0's rmse: 0.23033\n",
      "[100]\tvalid_0's rmse: 0.229803\n",
      "[120]\tvalid_0's rmse: 0.229427\n",
      "[140]\tvalid_0's rmse: 0.22912\n",
      "[160]\tvalid_0's rmse: 0.22885\n",
      "[180]\tvalid_0's rmse: 0.228633\n",
      "[200]\tvalid_0's rmse: 0.228469\n",
      "[220]\tvalid_0's rmse: 0.228336\n",
      "[240]\tvalid_0's rmse: 0.228177\n",
      "[260]\tvalid_0's rmse: 0.228062\n",
      "[280]\tvalid_0's rmse: 0.227967\n",
      "[300]\tvalid_0's rmse: 0.227872\n",
      "[320]\tvalid_0's rmse: 0.22781\n",
      "[340]\tvalid_0's rmse: 0.227729\n",
      "[360]\tvalid_0's rmse: 0.227643\n",
      "[380]\tvalid_0's rmse: 0.227562\n",
      "[400]\tvalid_0's rmse: 0.227508\n",
      "[420]\tvalid_0's rmse: 0.22741\n",
      "[440]\tvalid_0's rmse: 0.227362\n",
      "[460]\tvalid_0's rmse: 0.227301\n",
      "[480]\tvalid_0's rmse: 0.227266\n",
      "[500]\tvalid_0's rmse: 0.227223\n",
      "[520]\tvalid_0's rmse: 0.227193\n",
      "[540]\tvalid_0's rmse: 0.227144\n",
      "[560]\tvalid_0's rmse: 0.227101\n",
      "[580]\tvalid_0's rmse: 0.22708\n",
      "[600]\tvalid_0's rmse: 0.227044\n",
      "[620]\tvalid_0's rmse: 0.226997\n",
      "[640]\tvalid_0's rmse: 0.226971\n",
      "[660]\tvalid_0's rmse: 0.226944\n",
      "[680]\tvalid_0's rmse: 0.226914\n",
      "[700]\tvalid_0's rmse: 0.226861\n",
      "[720]\tvalid_0's rmse: 0.226837\n",
      "[740]\tvalid_0's rmse: 0.226786\n",
      "[760]\tvalid_0's rmse: 0.226755\n",
      "[780]\tvalid_0's rmse: 0.226711\n",
      "[800]\tvalid_0's rmse: 0.226695\n",
      "[820]\tvalid_0's rmse: 0.226683\n",
      "[840]\tvalid_0's rmse: 0.226656\n",
      "[860]\tvalid_0's rmse: 0.226629\n",
      "[880]\tvalid_0's rmse: 0.2266\n",
      "[900]\tvalid_0's rmse: 0.226595\n",
      "[920]\tvalid_0's rmse: 0.226578\n",
      "[940]\tvalid_0's rmse: 0.226553\n",
      "[960]\tvalid_0's rmse: 0.226537\n",
      "[980]\tvalid_0's rmse: 0.226516\n",
      "[1000]\tvalid_0's rmse: 0.226496\n",
      "[1020]\tvalid_0's rmse: 0.226468\n",
      "[1040]\tvalid_0's rmse: 0.22643\n",
      "[1060]\tvalid_0's rmse: 0.226415\n",
      "[1080]\tvalid_0's rmse: 0.226398\n",
      "[1100]\tvalid_0's rmse: 0.226388\n",
      "[1120]\tvalid_0's rmse: 0.226359\n",
      "[1140]\tvalid_0's rmse: 0.226357\n",
      "[1160]\tvalid_0's rmse: 0.226356\n",
      "[1180]\tvalid_0's rmse: 0.226338\n",
      "[1200]\tvalid_0's rmse: 0.226314\n",
      "[1220]\tvalid_0's rmse: 0.226296\n",
      "[1240]\tvalid_0's rmse: 0.226277\n",
      "[1260]\tvalid_0's rmse: 0.226265\n",
      "[1280]\tvalid_0's rmse: 0.226265\n",
      "[1300]\tvalid_0's rmse: 0.226256\n",
      "[1320]\tvalid_0's rmse: 0.226248\n",
      "[1340]\tvalid_0's rmse: 0.226226\n",
      "[1360]\tvalid_0's rmse: 0.226205\n",
      "[1380]\tvalid_0's rmse: 0.226183\n",
      "[1400]\tvalid_0's rmse: 0.226166\n",
      "[1420]\tvalid_0's rmse: 0.226138\n",
      "[1440]\tvalid_0's rmse: 0.226128\n",
      "[1460]\tvalid_0's rmse: 0.226111\n",
      "[1480]\tvalid_0's rmse: 0.2261\n",
      "[1500]\tvalid_0's rmse: 0.226098\n",
      "[1520]\tvalid_0's rmse: 0.226091\n",
      "[1540]\tvalid_0's rmse: 0.226071\n",
      "[1560]\tvalid_0's rmse: 0.226066\n",
      "[1580]\tvalid_0's rmse: 0.22605\n",
      "[1600]\tvalid_0's rmse: 0.226039\n",
      "[1620]\tvalid_0's rmse: 0.226036\n",
      "[1640]\tvalid_0's rmse: 0.226032\n",
      "[1660]\tvalid_0's rmse: 0.226026\n",
      "[1680]\tvalid_0's rmse: 0.226009\n",
      "[1700]\tvalid_0's rmse: 0.225996\n",
      "[1720]\tvalid_0's rmse: 0.22599\n",
      "[1740]\tvalid_0's rmse: 0.225981\n",
      "[1760]\tvalid_0's rmse: 0.225968\n",
      "[1780]\tvalid_0's rmse: 0.225955\n",
      "[1800]\tvalid_0's rmse: 0.225934\n",
      "[1820]\tvalid_0's rmse: 0.225911\n",
      "[1840]\tvalid_0's rmse: 0.225903\n",
      "[1860]\tvalid_0's rmse: 0.225887\n",
      "[1880]\tvalid_0's rmse: 0.22588\n",
      "[1900]\tvalid_0's rmse: 0.225873\n",
      "[1920]\tvalid_0's rmse: 0.225869\n",
      "[1940]\tvalid_0's rmse: 0.225866\n",
      "[1960]\tvalid_0's rmse: 0.225872\n",
      "[1980]\tvalid_0's rmse: 0.225855\n",
      "[2000]\tvalid_0's rmse: 0.225854\n",
      "[2020]\tvalid_0's rmse: 0.225849\n",
      "[2040]\tvalid_0's rmse: 0.225844\n",
      "[2060]\tvalid_0's rmse: 0.225834\n",
      "[2080]\tvalid_0's rmse: 0.225832\n",
      "[2100]\tvalid_0's rmse: 0.225826\n",
      "[2120]\tvalid_0's rmse: 0.225821\n",
      "[2140]\tvalid_0's rmse: 0.225821\n",
      "[2160]\tvalid_0's rmse: 0.225813\n",
      "[2180]\tvalid_0's rmse: 0.225815\n",
      "[2200]\tvalid_0's rmse: 0.225801\n",
      "[2220]\tvalid_0's rmse: 0.22579\n",
      "[2240]\tvalid_0's rmse: 0.225793\n",
      "[2260]\tvalid_0's rmse: 0.225785\n",
      "[2280]\tvalid_0's rmse: 0.225784\n",
      "[2300]\tvalid_0's rmse: 0.225778\n",
      "[2320]\tvalid_0's rmse: 0.225771\n",
      "[2340]\tvalid_0's rmse: 0.225765\n",
      "[2360]\tvalid_0's rmse: 0.225757\n",
      "[2380]\tvalid_0's rmse: 0.22575\n",
      "[2400]\tvalid_0's rmse: 0.22575\n",
      "[2420]\tvalid_0's rmse: 0.225737\n",
      "[2440]\tvalid_0's rmse: 0.22573\n",
      "[2460]\tvalid_0's rmse: 0.225721\n",
      "[2480]\tvalid_0's rmse: 0.225714\n",
      "[2500]\tvalid_0's rmse: 0.2257\n",
      "[2520]\tvalid_0's rmse: 0.2257\n",
      "[2540]\tvalid_0's rmse: 0.225698\n",
      "[2560]\tvalid_0's rmse: 0.225699\n",
      "[2580]\tvalid_0's rmse: 0.225694\n",
      "[2600]\tvalid_0's rmse: 0.225693\n",
      "[2620]\tvalid_0's rmse: 0.225684\n",
      "[2640]\tvalid_0's rmse: 0.22568\n",
      "[2660]\tvalid_0's rmse: 0.225676\n",
      "[2680]\tvalid_0's rmse: 0.225665\n",
      "[2700]\tvalid_0's rmse: 0.225662\n",
      "[2720]\tvalid_0's rmse: 0.225662\n",
      "[2740]\tvalid_0's rmse: 0.225655\n",
      "[2760]\tvalid_0's rmse: 0.225649\n",
      "[2780]\tvalid_0's rmse: 0.22565\n",
      "[2800]\tvalid_0's rmse: 0.225645\n",
      "[2820]\tvalid_0's rmse: 0.225646\n",
      "[2840]\tvalid_0's rmse: 0.225649\n",
      "[2860]\tvalid_0's rmse: 0.225644\n",
      "[2880]\tvalid_0's rmse: 0.225631\n",
      "[2900]\tvalid_0's rmse: 0.225634\n",
      "[2920]\tvalid_0's rmse: 0.225628\n",
      "[2940]\tvalid_0's rmse: 0.225624\n",
      "[2960]\tvalid_0's rmse: 0.22562\n",
      "[2980]\tvalid_0's rmse: 0.22562\n",
      "[3000]\tvalid_0's rmse: 0.225613\n",
      "[3020]\tvalid_0's rmse: 0.225613\n",
      "[3040]\tvalid_0's rmse: 0.225605\n",
      "[3060]\tvalid_0's rmse: 0.225608\n",
      "[3080]\tvalid_0's rmse: 0.225608\n",
      "[3100]\tvalid_0's rmse: 0.225606\n",
      "[3120]\tvalid_0's rmse: 0.225595\n",
      "[3140]\tvalid_0's rmse: 0.225596\n",
      "[3160]\tvalid_0's rmse: 0.225595\n",
      "[3180]\tvalid_0's rmse: 0.225596\n",
      "[3200]\tvalid_0's rmse: 0.225604\n",
      "[3220]\tvalid_0's rmse: 0.225601\n",
      "[3240]\tvalid_0's rmse: 0.225594\n",
      "[3260]\tvalid_0's rmse: 0.225593\n",
      "[3280]\tvalid_0's rmse: 0.225594\n",
      "[3300]\tvalid_0's rmse: 0.2256\n",
      "[3320]\tvalid_0's rmse: 0.225598\n",
      "[3340]\tvalid_0's rmse: 0.225603\n",
      "[3360]\tvalid_0's rmse: 0.225607\n",
      "[3380]\tvalid_0's rmse: 0.225609\n",
      "[3400]\tvalid_0's rmse: 0.225609\n",
      "[3420]\tvalid_0's rmse: 0.225608\n",
      "Early stopping, best iteration is:\n",
      "[3270]\tvalid_0's rmse: 0.225588\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
