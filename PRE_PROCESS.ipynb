{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# speed up the loop\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "# read testing data\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2011862, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat train and test data that part used for train and the rest used for validation\n",
    "combined_data = pd.concat([train_data, test_data],axis=0)\n",
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data[\"image_top_1\"].fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feature = ['param_1','param_2','param_3',\"description\", \"title\"]\n",
    "for cols in text_feature:\n",
    "    combined_data[cols] = combined_data[cols].astype(str) \n",
    "    combined_data[cols] = combined_data[cols].astype(str).fillna('NaN') # FILL NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price feature\n",
    "combined_data[\"price\"] = np.log(combined_data[\"price\"]+0.001)\n",
    "combined_data[\"price\"].fillna(combined_data.price.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data convert for feature engineering \n",
    "# feature of day, weekday, and week (error)\n",
    "train_data.activation_date = pd.to_datetime(train_data.activation_date)\n",
    "train_data['day_of_month'] = train_data.activation_date.apply(lambda x: x.day)\n",
    "train_data['day_of_week'] = train_data.activation_date.apply(lambda x: x.weekday())\n",
    "#train_data['week_of_year'] = train_data.activation_date.apply(lambda x: x.week())\n",
    "train_data['week_of_year'] = train_data.activation_date.dt.week\n",
    "\n",
    "\n",
    "# converted for whole dataset\n",
    "combined_data.activation_date = pd.to_datetime(combined_data.activation_date)\n",
    "combined_data['day_of_month'] = combined_data.activation_date.apply(lambda x: x.day)\n",
    "combined_data['day_of_week'] = combined_data.activation_date.apply(lambda x: x.weekday())\n",
    "#combined_data['week_of_year'] = combined_data.activation_date.apply(lambda x: x.week())\n",
    "combined_data['week_of_year'] = combined_data.activation_date.dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.80it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "category_column = ['region','city','parent_category_name','category_name','user_type','image_top_1','item_seq_number','day_of_month','day_of_week','week_of_year']\n",
    "for item in tqdm(category_column):\n",
    "        groupBy = train_data.groupby(item)['deal_probability']\n",
    "        mean = groupBy.mean()\n",
    "        std = groupBy.std()\n",
    "        combined_data[item + '_deal_probability_mean'] = combined_data[item].map(mean)\n",
    "        combined_data[item + '_deal_probability_mean'].fillna(0,inplace=True)\n",
    "        combined_data[item + '_deal_probability_std'] = combined_data[item].map(std)\n",
    "        combined_data[item + '_deal_probability_std'].fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "for item in tqdm(category_column):\n",
    "        groupBy = train_data.groupby(item)['price']\n",
    "        mean = groupBy.mean()\n",
    "        std = groupBy.std()\n",
    "        combined_data[item + '_price_mean'] = combined_data[item].map(mean)\n",
    "        combined_data[item + '_price_mean'].fillna(0,inplace=True)\n",
    "        combined_data[item + '_price_std'] = combined_data[item].map(std)\n",
    "        combined_data[item + '_price_std'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute description tf-idf for whole dataset\n",
    "\n",
    "# fill NaN as blank\n",
    "combined_data['description'] = combined_data['description'].fillna(' ')\n",
    "# test on different value of max_features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 100,\n",
    "                                   stop_words=stopwords.words('russian'))\n",
    "tfidf_matrix = np.array(tfidf_vectorizer.fit_transform(combined_data['description']).todense(),dtype=np.float16)\n",
    "# assign tf-idf into dataframe\n",
    "for i in range(100):\n",
    "    combined_data['tf_idf_' + str(i)] = tfidf_matrix[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN as blank\n",
    "combined_data['title'] = combined_data['title'].fillna(' ')\n",
    "# test on different value of max_features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features = 50,\n",
    "                                   stop_words=stopwords.words('russian'))\n",
    "tfidf_matrix = np.array(tfidf_vectorizer.fit_transform(combined_data['title']).todense(),dtype=np.float16)\n",
    "# assign tf-idf into dataframe\n",
    "for i in range(50):\n",
    "    combined_data['tf_idf_title_' + str(i)] = tfidf_matrix[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels with value between 0 and n-classes-1 for whole dataset\n",
    "category_column_new = ['region','city','parent_category_name','category_name','user_type','param_1','param_2','param_3','image_top_1']\n",
    "for item in category_column_new:\n",
    "    combined_data[item].fillna('NaN')\n",
    "    combined_data[item] = LabelEncoder().fit_transform(combined_data[item].astype(str)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean title and text by removing special characters\n",
    "# fcn for cleaing words\n",
    "def clean_word(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['title'] = combined_data['title'].apply(lambda x: clean_word(x))\n",
    "combined_data[\"description\"]   = combined_data[\"description\"].apply(lambda x: clean_word(x))\n",
    "\n",
    "text_feature = [\"description\", \"title\"]\n",
    "\n",
    "for cols in text_feature:\n",
    "    combined_data[cols] = combined_data[cols].astype(str) \n",
    "    combined_data[cols] = combined_data[cols].astype(str).fillna('NaN') # FILL NaN\n",
    "    combined_data[cols] = combined_data[cols].str.lower() \n",
    "    combined_data[cols + '_length'] = combined_data[cols].apply(lambda x: len(x.split()))\n",
    "    combined_data[cols + '_length'].fillna(0,inplace=True)\n",
    "    combined_data[cols + '_num_unique_words'] = combined_data[cols].apply(lambda x: len(set(w for w in x.split())))\n",
    "    combined_data[cols + '_num_unique_words'].fillna(0,inplace=True)\n",
    "    combined_data[cols + '_unique_percentage'] = combined_data[cols+'_num_unique_words'] / combined_data[cols+'_length'] * 100\n",
    "    combined_data[cols + '_unique_percentage'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def combine_dataframe(df1, df2):\n",
    "    result = df1.append(df2)\n",
    "    return result\n",
    "\n",
    "def combine_feature(d1,d2):\n",
    "    result = pd.concat([d1, d2],axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_period = pd.read_pickle('period.p')\n",
    "test_period = pd.read_pickle('test_period.p')\n",
    "combined_period = combine_dataframe(train_period, test_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_price_rank = pd.read_pickle('price_rank_train.p')\n",
    "test_price_rank = pd.read_pickle('price_rank_test.p')\n",
    "combined_price_rank = combine_dataframe(train_price_rank, test_price_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_IMG = pd.read_pickle('df_train')\n",
    "test_IMG = pd.read_pickle('df_test')\n",
    "combined_IMG = combine_dataframe(train_IMG, test_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([combined_data, combined_period, combined_price_rank, combined_IMG], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = result.drop(['user_id', 'description', 'image', 'item_id', 'title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = result.drop(['deal_probability','image'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activation_date                                    0\n",
       "category_name                                      0\n",
       "city                                               0\n",
       "description                                        0\n",
       "image                                         155197\n",
       "image_top_1                                        0\n",
       "item_id                                            0\n",
       "item_seq_number                                    0\n",
       "param_1                                            0\n",
       "param_2                                            0\n",
       "param_3                                            0\n",
       "parent_category_name                               0\n",
       "price                                              0\n",
       "region                                             0\n",
       "title                                              0\n",
       "user_id                                            0\n",
       "user_type                                          0\n",
       "day_of_month                                       0\n",
       "day_of_week                                        0\n",
       "week_of_year                                       0\n",
       "region_deal_probability_mean                       0\n",
       "region_deal_probability_std                        0\n",
       "city_deal_probability_mean                         0\n",
       "city_deal_probability_std                          0\n",
       "parent_category_name_deal_probability_mean         0\n",
       "parent_category_name_deal_probability_std          0\n",
       "category_name_deal_probability_mean                0\n",
       "category_name_deal_probability_std                 0\n",
       "user_type_deal_probability_mean                    0\n",
       "user_type_deal_probability_std                     0\n",
       "                                               ...  \n",
       "tf_idf_title_30                                    0\n",
       "tf_idf_title_31                                    0\n",
       "tf_idf_title_32                                    0\n",
       "tf_idf_title_33                                    0\n",
       "tf_idf_title_34                                    0\n",
       "tf_idf_title_35                                    0\n",
       "tf_idf_title_36                                    0\n",
       "tf_idf_title_37                                    0\n",
       "tf_idf_title_38                                    0\n",
       "tf_idf_title_39                                    0\n",
       "tf_idf_title_40                                    0\n",
       "tf_idf_title_41                                    0\n",
       "tf_idf_title_42                                    0\n",
       "tf_idf_title_43                                    0\n",
       "tf_idf_title_44                                    0\n",
       "tf_idf_title_45                                    0\n",
       "tf_idf_title_46                                    0\n",
       "tf_idf_title_47                                    0\n",
       "tf_idf_title_48                                    0\n",
       "tf_idf_title_49                                    0\n",
       "description_length                                 0\n",
       "description_num_unique_words                       0\n",
       "description_unique_percentage                     21\n",
       "title_length                                       0\n",
       "title_num_unique_words                             0\n",
       "title_unique_percentage                            0\n",
       "diff                                               0\n",
       "price_rank1                                        0\n",
       "image_top_1                                        0\n",
       "image_y_or_n                                       0\n",
       "Length: 220, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.drop(['deal_probability','image'],axis=1).isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activation_date                               False\n",
       "category_name                                 False\n",
       "city                                          False\n",
       "deal_probability                               True\n",
       "image_top_1                                   False\n",
       "item_seq_number                               False\n",
       "param_1                                       False\n",
       "param_2                                       False\n",
       "param_3                                       False\n",
       "parent_category_name                          False\n",
       "price                                         False\n",
       "region                                        False\n",
       "user_type                                     False\n",
       "day_of_month                                  False\n",
       "day_of_week                                   False\n",
       "week_of_year                                  False\n",
       "region_deal_probability_mean                  False\n",
       "region_deal_probability_std                   False\n",
       "city_deal_probability_mean                    False\n",
       "city_deal_probability_std                     False\n",
       "parent_category_name_deal_probability_mean    False\n",
       "parent_category_name_deal_probability_std     False\n",
       "category_name_deal_probability_mean           False\n",
       "category_name_deal_probability_std            False\n",
       "user_type_deal_probability_mean               False\n",
       "user_type_deal_probability_std                False\n",
       "image_top_1_deal_probability_mean             False\n",
       "image_top_1_deal_probability_std              False\n",
       "item_seq_number_deal_probability_mean         False\n",
       "item_seq_number_deal_probability_std          False\n",
       "                                              ...  \n",
       "tf_idf_title_30                               False\n",
       "tf_idf_title_31                               False\n",
       "tf_idf_title_32                               False\n",
       "tf_idf_title_33                               False\n",
       "tf_idf_title_34                               False\n",
       "tf_idf_title_35                               False\n",
       "tf_idf_title_36                               False\n",
       "tf_idf_title_37                               False\n",
       "tf_idf_title_38                               False\n",
       "tf_idf_title_39                               False\n",
       "tf_idf_title_40                               False\n",
       "tf_idf_title_41                               False\n",
       "tf_idf_title_42                               False\n",
       "tf_idf_title_43                               False\n",
       "tf_idf_title_44                               False\n",
       "tf_idf_title_45                               False\n",
       "tf_idf_title_46                               False\n",
       "tf_idf_title_47                               False\n",
       "tf_idf_title_48                               False\n",
       "tf_idf_title_49                               False\n",
       "description_length                            False\n",
       "description_num_unique_words                  False\n",
       "description_unique_percentage                 False\n",
       "title_length                                  False\n",
       "title_num_unique_words                        False\n",
       "title_unique_percentage                       False\n",
       "diff                                          False\n",
       "price_rank1                                   False\n",
       "image_top_1                                   False\n",
       "image_y_or_n                                  False\n",
       "Length: 216, dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_pickle('final_data_V1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_data.loc[final_data.activation_date<=pd.to_datetime('2017-04-07')]\n",
    "X_test = final_data.loc[final_data.activation_date>=pd.to_datetime('2017-04-08')]\n",
    "\n",
    "Y = X.deal_probability\n",
    "X = X.drop(['activation_date', 'deal_probability'], axis=1)\n",
    "X_test = X_test.drop(['activation_date', 'deal_probability'], axis=1)\n",
    "\n",
    "# split train and validation\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a model by providing X and y from training set\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19712851149796884"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19709747791083443"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_validation, Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_predict = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2330299656985343"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(Y_train_predict, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validat_predict = clf.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2330762616375686"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(Y_validat_predict, Y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
